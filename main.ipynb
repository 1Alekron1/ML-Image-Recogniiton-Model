{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "-zDvITaiFsoz",
    "outputId": "613f4277-db19-4cde-8cd5-552a653a3482",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import torchvision\n",
    "from livelossplot import PlotLossesKeras\n",
    "from numpy import ndarray\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Работа с данными"
   ],
   "metadata": {
    "collapsed": false,
    "id": "pV8coj4DFso0",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Функция, которая будет убирать \"битые пиксели\" с картинки, заполнять их средним значением из соседних восьми.\n",
    "**Работает очень долго, но получается очень хорошо.**"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ZOXKMm8rFso1",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def defective_pixels(images_data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "\n",
    "    :param images_data: np.ndarray - массив изображений (исходный датасет)\n",
    "    :return: np.ndarray[np.ndarray]\n",
    "\n",
    "    Функция, которая убирает битые пиксели,\n",
    "    заполняя их средним значением ближайших\n",
    "    \"\"\"\n",
    "\n",
    "    def get_median_for_pixel(img: int, loc_row: int, loc_col: int, chanel: int):\n",
    "        \"\"\"\n",
    "        :param img: изображение из датасета\n",
    "        :param loc_row: строка пикселя\n",
    "        :param loc_col: ряд пикселя\n",
    "        :param chanel: канал (одно из 0, 1, 2)\n",
    "        :return: медиану\n",
    "        \"\"\"\n",
    "\n",
    "        return np.median(\n",
    "            [\n",
    "                images_data[img][loc_row - 1][loc_col + 0][chanel], images_data[img][loc_row - 1][loc_col - 1][chanel],\n",
    "                images_data[img][loc_row - 1][loc_col + 1][chanel], images_data[img][loc_row + 1][loc_col + 0][chanel],\n",
    "                images_data[img][loc_row + 1][loc_col - 1][chanel], images_data[img][loc_row + 1][loc_col + 1][chanel],\n",
    "                images_data[img][loc_row + 0][loc_col + 1][chanel], images_data[img][loc_row + 0][loc_col - 1][chanel]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    images_count = len(images_data)\n",
    "    image_width = len(images_data[1])\n",
    "    image_height = len(images_data[1][1])\n",
    "\n",
    "    for im in range(images_count):\n",
    "        for row in range(1, image_width - 1):\n",
    "            for px in range(1, image_height - 1):\n",
    "                if (\n",
    "                        np.array_equal(images_data[im][row][px], np.array([1., 1., 1.])) or\n",
    "                        np.array_equal(images_data[im][row][px], np.array([0., 0., 0.]))\n",
    "                ):\n",
    "                    images_data[im][row][px] = np.array([\n",
    "                        get_median_for_pixel(im, row, px, 0),\n",
    "                        get_median_for_pixel(im, row, px, 1),\n",
    "                        get_median_for_pixel(im, row, px, 2)\n",
    "                    ])\n",
    "\n",
    "    return images_data[0:len(images_data), 1:-1, 1:-1, 0:3]"
   ],
   "metadata": {
    "id": "IeVhBpSAFso1",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Функции загрузки и сохранения датасетов**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_data(file_name: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :param file_name: path to dataset\n",
    "    :return: dataset\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_name, 'rb') as input_file:\n",
    "        return pickle.load(input_file)\n",
    "\n",
    "\n",
    "def write_data(file_name: str, data) -> None:\n",
    "    \"\"\"\n",
    "    :param file_name: path to dataset\n",
    "    :param data: data of dataset\n",
    "    :return: dataset\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_name, 'wb') as output_file:\n",
    "        pickle.dump(data, output_file)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "VUXGfMViFso2",
    "outputId": "1c59c45d-549c-4b7e-e7b5-3b65f2df1a6b",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Грузим трейновый датасет, сохраняем лейблы\n",
    "\n",
    "df = load_data('./DATA/data_train')\n",
    "labels = df['labels']"
   ],
   "metadata": {
    "id": "XTP3bbGhFso2",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Обработка (очень долго, спускайтесь на 2 ячейки вниз)\n",
    "arr = df['images'].astype(np.uint8)\n",
    "# Деление на 255 - самая простая нормализация данных. Все значения конвертируются в промежуток [0;1]\n",
    "arr = defective_pixels(arr / 255.)"
   ],
   "metadata": {
    "id": "9ksV52AsFso2",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "write_data('./DATA/arr.np.ndarray', arr)"
   ],
   "metadata": {
    "id": "WpP8ZmC9Fso3",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Загружаем переменную arr чтобы не ждать работы функций обрабатывающих датасет\n",
    "\n",
    "arr = load_data('./DATA/arr.np.ndarray')"
   ],
   "metadata": {
    "id": "h79t1q5zFso3",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Аугментация. Создаем последовательность преобразований фото. Используем [torchvision](https://pytorch.org/vision/stable/index.html), т.к. tensorflow предоставляет крайне скудный функционал."
   ],
   "metadata": {
    "collapsed": false,
    "id": "_cHVTQsJFso3",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Небольшое отступление насчет аугментаций*\n",
    "*Весь смысл выполнения аугментации - преобразования данных таким образом,\n",
    "чтобы итоговая модель смогла обрабатывать более нестандартные случаи, чем она увидела в трейне.\n",
    "Модель должна каждый раз видеть разные фотки. Также очень важно делать так,\n",
    " чтобы аугментация происходила **случайным** образом, **во время обучения** модели.\n",
    " Такой подход позволяет практически полностью избавиться от переобучения, не искажает сути этой техники*\n"
   ],
   "metadata": {
    "id": "1tlP8oPBHF6h",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomAffine(degrees=3, scale=(.8, 1.1)),\n",
    "    # Афинное преобразование - универсальный инструмент аугментации\n",
    "    torchvision.transforms.RandomPerspective(.3),  # Небольшая перспектива поможет модели отпределять кривые цифры \n",
    "    torchvision.transforms.RandomAutocontrast(),\n",
    "    # Следующие 3 аугметации были выбраны исходя из различия цветовых гамм на фотках.\n",
    "    torchvision.transforms.ColorJitter(.5, .5, .5, .4),\n",
    "    torchvision.transforms.RandomInvert(.5),\n",
    "])\n",
    "#  Мы также пробовали преобразовать фото в градации серого,\n",
    "#  это логически должно было помочь, но этот метод показал наилучший результат."
   ],
   "metadata": {
    "id": "O7VYDdztFso3",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[\\*тык*](https://pytorch.org/vision/main/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py) чтобы лицезреть аугментации"
   ],
   "metadata": {
    "id": "HBjCOOSLIs2s",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Для того чтобы аугментация выполнялась по ходу запроса батчей информации, создаем свой класс,\n",
    "который будем передавать в качестве датасета в model.fit().\n",
    "Наследуемся от [tf.keras.utils.Sequence](https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence).**"
   ],
   "metadata": {
    "collapsed": false,
    "id": "1G4snsgVFso4",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MySequence(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        \"\"\"\n",
    "        :param x_set: последовательность картинок\n",
    "        :param y_set: последовательность лейблов\n",
    "        :param batch_size: размер батча\n",
    "        \"\"\"\n",
    "\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        :param idx: индекс начала батча в датасете\n",
    "        :return: батч информации\n",
    "        \"\"\"\n",
    "\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return (\n",
    "            np.array([np.asarray(transform(Image.fromarray(np.uint8(x)))) / 255. for x in batch_x]),\n",
    "            np.array(batch_y)\n",
    "        )"
   ],
   "metadata": {
    "id": "7UGeqMECFso4",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Посмотрим на обработанный датасет**"
   ],
   "metadata": {
    "collapsed": false,
    "id": "0MktuGxEFso4",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(np.array(arr[i]))\n",
    "    plt.xlabel(labels[i])\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "jVNz0JIoFso4",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arr = np.uint8(arr * 255)"
   ],
   "metadata": {
    "id": "rhF2ElH6Fso4",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arr, validation_images, labels, validation_labels = train_test_split(arr, labels, test_size=0.07)"
   ],
   "metadata": {
    "id": "mZRpbuAiFso4",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validation_images = validation_images / 255.  # нормализация данных"
   ],
   "metadata": {
    "id": "fUH2YL2qFso4",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTdnWeCjFso5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256  # Объявляем размер батча. Поставил 256 потому что могу\n",
    "ds = MySequence(arr, labels, batch_size=batch_size)  # создаем Sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kp4-fA1sFso5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    validation_images,\n",
    "    validation_labels\n",
    "))  # валидационный датасет не аугментируется, поэтому создаем его через tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2Eofn96Fso5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ф-ция, обрабатывающая трейновый датасет урезает по пикселю с каждой стороны. Они не несут большого кол-ва информации, поэтому это не страшно.\n",
    "input_shape = 30, 30, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9rpMsd2Fso5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# батчируем валидационный датасет\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Модель\n",
    "#### 2.1.1 [Center Crop](https://www.tensorflow.org/api_docs/python/tf/keras/layers/CenterCrop) обрезает 10 боковых пикселей. От нас требуется определение централной цифры (на картинке их бывает несколько). Модель может случайно вытащить фичи из соседних цифр, поэтому их можно обрезать. Широкие цифры, которым мы обрежем бока, в большинстве своем сохранят свои главные фичи.\n",
    "#### 2.1.2 Модель имеет 6 сверточных блоков, соединенных скип-коннекшнами. Постепенное увеличение информации за счет увеличения каналов (32 -> 64 -> 128). Чтобы картинка не самоуничтожилась, включаем паддинг.\n",
    "#### 2.1.3 После выделения признаков идет 2 полносвязных слоя. Этого достаточно для связывания признаков с выходными классами.\n",
    "#### 2.1.4 Модель достаточно глубокая, требует много времени для обучения, но цель оправдывает средства.\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ZCawOKs8Fso5",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgoHlanwFso5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=input_shape)\n",
    "c = tf.keras.layers.CenterCrop(28, 20)(input_layer)\n",
    "\n",
    "# Первый блок:\n",
    "b1l1 = tf.keras.layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(c)\n",
    "b1l2 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(b1l1)\n",
    "b1_output = tf.keras.layers.MaxPooling2D()(b1l2)\n",
    "\n",
    "# Второй блок:\n",
    "b2l1 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(b1_output)\n",
    "b2l2 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(b2l1)\n",
    "\n",
    "# Связываем эти 2 блока\n",
    "b2b1_output = tf.keras.layers.add([b2l2, b1_output])\n",
    "\n",
    "# Третий блок:\n",
    "b3l1 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(b2b1_output)\n",
    "b3l2 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(b3l1)\n",
    "\n",
    "# Связываем эти 2 блока\n",
    "block_3_output = tf.keras.layers.add([b3l2, b2b1_output])\n",
    "\n",
    "b4l1 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_3_output)\n",
    "b4l2 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(b4l1)\n",
    "\n",
    "block_4_output = tf.keras.layers.add([block_3_output, b4l2])\n",
    "\n",
    "b5l1 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_4_output)\n",
    "b5l2 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(b5l1)\n",
    "\n",
    "block_5_output = tf.keras.layers.add([block_4_output, b5l2])\n",
    "\n",
    "b6l1 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_5_output)\n",
    "b6l2 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(b6l1)\n",
    "\n",
    "block_6_output = tf.keras.layers.add([block_5_output, b6l2])\n",
    "\n",
    "l1 = tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_6_output)\n",
    "#tmp = tf.keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(l1)\n",
    "l2 = tf.keras.layers.GlobalAveragePooling2D()(l1)\n",
    "l4 = tf.keras.layers.Dense(256, activation=\"relu\")(l2)\n",
    "bn = tf.keras.layers.BatchNormalization()(l4)\n",
    "l5 = tf.keras.layers.Dropout(.05)(bn)\n",
    "outputs = tf.keras.layers.Dense(10)(l5)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**В ходе экпериментов мы решили попробовать модель немного попроще.\n",
    "Избавившись от паддинга и скип коннекшнов (больше по сути ничего не поменялось)\n",
    "Мы получили огромный прирост к метрике (+0.01)**"
   ],
   "metadata": {
    "id": "eXpyFRYIJL25",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "modseq = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(30, 30, 3)),\n",
    "    tf.keras.layers.CenterCrop(28, 20),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ],
   "metadata": {
    "id": "YBgLWXwmFso6",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkO2WFLJFso6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_kaggle = tf.keras.Model(input_layer, outputs, name=\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2.1 Коллбеки-чекпоинты"
   ],
   "metadata": {
    "collapsed": false,
    "id": "8FWeReaCFso6",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.1.1 В tf есть возможность делать чекпоинты с помощью коллбеков (по аналогу с PlotLosses). Мы делаем 4 чекпоинта: по лоссу, аккураси, последняя модель, средняя модель.\n",
    "#### 2.2.1.2 [tfa.callbacks.AverageModelCheckpoint](https://www.tensorflow.org/addons/api_docs/python/tfa/callbacks/AverageModelCheckpoint) [усредняет веса](https://towardsdatascience.com/stochastic-weight-averaging-a-new-way-to-get-state-of-the-art-results-in-deep-learning-c639ccf36a) последних выделившихся по метрикам моделей. Допустим, модель на 170-й эпохе выделяется определением кривых двоек, а на 180-й хорошо выделяет фичи 6 и 8. Усреднение весов помогает объединить эти навыки, хорошо прибавляет к итоговой метрике."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "checkpoint_filepath = './CHECKPOINTS/modseq/acc'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "checkpoint_filepath = './CHECKPOINTS/modseq/loss'\n",
    "model_checkpoint_callback2 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "checkpoint_filepath = './CHECKPOINTS/modseq/freq'\n",
    "model_checkpoint_callback3 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "checkpoint_filepath = './CHECKPOINTS/modseq/avg'\n",
    "model_checkpoint_callback4 = tfa.callbacks.AverageModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    update_weights=True,\n",
    "    save_weights_only=False\n",
    ")"
   ],
   "metadata": {
    "id": "LVXcgHATFso6",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2.2 [lr-scheduler](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler)\n",
    "\n",
    "**При обучении модели, ближе к концу обучения (около 200-й эпохи),\n",
    " модель находится около оптимума, но из-за большого lr перескакивает его.\n",
    " Для этого можно использовать шедулер который понижает lr по мере приближения к n-ной эпохе.\n",
    " К сожалению, этот экспириенс не оказался положительным.\n",
    " Думаю, при таких высоких метриках играет роль случайность,\n",
    " это и стало причиной того, что lr-scheduler не сыграл.**"
   ],
   "metadata": {
    "collapsed": false,
    "id": "HNkjyU9vFso6",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr_sheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    1e-3,\n",
    "    200,\n",
    "    end_learning_rate=1e-4,\n",
    "    power=1.0,\n",
    "    cycle=False,\n",
    "    name=None\n",
    ")"
   ],
   "metadata": {
    "id": "33ZyFvoRFso7",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2.3 Оптимизатор\n",
    "#### 2.2.3.1 В качестве оптимизатора мы выбрали [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam), ведь он идеально подходит для нашей классификации. В параметры мы передаем [Weight-decay](https://www.fast.ai/posts/2018-07-02-adam-weight-decay.html), эта регуляризация очень хорошо помогает бороться с переобучением. За счет более длительного обучения мы получили очень хороший результат.\n",
    "#### 2.2.3.2 [MovingAverage](https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/MovingAverage) - применяется к оптимизатору, позволяет работать с усреднением весов в коллбеке"
   ],
   "metadata": {
    "collapsed": false,
    "id": "iKg31hylFso7",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(decay=4e-5)\n",
    "opt = tfa.optimizers.MovingAverage(adam)"
   ],
   "metadata": {
    "id": "PKcwOgrqFso7",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "modseq.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "modseq.summary()"
   ],
   "metadata": {
    "id": "epdLY2ZPFso7",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J872OyNsFso7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_kaggle.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_kaggle.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iUnJQe3Fso8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modseqh = modseq.fit(\n",
    "    ds,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=400,\n",
    "    callbacks=[\n",
    "        PlotLossesKeras(),\n",
    "        model_checkpoint_callback,\n",
    "        model_checkpoint_callback2,\n",
    "        model_checkpoint_callback3,\n",
    "        model_checkpoint_callback4\n",
    "    ],\n",
    "    verbose=False,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dftest = load_data('./DATA/data_test')\n",
    "arrtest = dftest['images']"
   ],
   "metadata": {
    "id": "M35bpOMWFso8",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "arrtest = np.uint8(arrtest) / 255.\n",
    "arrtest = defective_pixels(arrtest)\n",
    "arrtest[0]"
   ],
   "metadata": {
    "id": "fMbZUptzFso8",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-vQaXG0HFso9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = modseq.predict(arrtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classes = np.argmax(predictions, axis=1)\n",
    "classes\n",
    "# 5 4 1 ... 0 9 2"
   ],
   "metadata": {
    "id": "YzB8GC0kFso9",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9ANuD2ZFso9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for i, j in zip(range(99, 110), range(9)):\n",
    "    plt.subplot(3, 3, j + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(np.array(arrtest[i]))\n",
    "    plt.xlabel(classes[i])\n",
    "plt.show()  # смотрим на предсказанные фоточки"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2.4 [Ансамблирование](https://en.wikipedia.org/wiki/Ensemble_learning)\n",
    "**Изучив этот метод объединения моделей, метрики сильно выросли.\n",
    "Эта технкиа очень схожа с п. 2.2.1.2 (усреднение весов), но она обрабатывает только выход головы (логитов).\n",
    " Комментарии излишни, прочитав статью можно все понять. Примерное использование ансамблирования в ячейках ниже**"
   ],
   "metadata": {
    "id": "lbDCE5OdKBm4",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ансамблирование\n",
    "mod1 = tf.keras.models.load_model('./CHECKPOINTS/easymodel/acc')\n",
    "mod2 = tf.keras.models.load_model('./CHECKPOINTS/easymodel/freq')\n",
    "mod3 = tf.keras.models.load_model('./CHECKPOINTS/easymodel/loss')\n",
    "mod4 = tf.keras.models.load_model('./CHECKPOINTS/easymodel/avg')\n",
    "\n",
    "k = np.rot90([\n",
    "    i.predict(arrtest)\n",
    "    for i in [mod1, mod2, mod3, mod4]\n",
    "])"
   ],
   "metadata": {
    "id": "BWtMlYQ6Fso-",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classes = list(np.argmax(k.mean(axis=1), axis=1))\n",
    "classes.reverse()"
   ],
   "metadata": {
    "id": "VKRGjqhOFso-",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classes"
   ],
   "metadata": {
    "id": "Fk8l50UiFso-",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Дальше дело за малым, сохраняем решение, заливаем на кеглю"
   ],
   "metadata": {
    "id": "jnUIwQRPL10w",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('easyassamble.csv', 'w') as f:\n",
    "    f.write('Id,Category\\n')\n",
    "    for i, j in enumerate(classes):\n",
    "        f.write(f'{i},{j}\\n')"
   ],
   "metadata": {
    "id": "CNiMxlNdFso_",
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# То, что мы изучили, но в ноутбук это не вошло\n",
    "*сквозная нумерация тут заканчивается\n",
    "\n",
    "1.  Разные виды нормализации\n",
    "[Пакетная нормализация](https://machinelearningmastery.ru/batch-normalization-and-dropout-in-neural-networks-explained-with-pytorch-47d7a8459bcd/) не дала прироста к метрикам, работала странно.\n",
    "[MinMax Scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) тоже не помог. Остановились на классической нормализации делением на 255, она самая нейтральная.\n",
    "\n",
    "\n",
    "2.  Тонкая настройка, настройка головы модели.\n",
    "К сожалению чекпоинт ноутбука с этим введением был утерян. Смысл ее в том, что модель делится на 2 блока - выделение признаков (сверточный блок), голова, которая связывает выделенные фичи с классами. Часто бывает так, что эти 2 \"блока\" обучаются неравномерно, выделение признаков делает это раньше, чем голова модели. Для этого можно обучать вторую часть отдельно. Тензорфлоу похволяет это делать, если объединить эти 2 блока в модель Sequential, в момент достаточного обучения первой части можно поставить флаг non-trainable, продолжить обучение головы.\n",
    "\n",
    "3.  [Паддинг](https://www.geeksforgeeks.org/cnn-introduction-to-padding/)\n",
    "Эксперименты с паддингом не увенчались успехом, добились +аккураси только путем уменьшения числа сверточных слоев и отказа от паддинга."
   ],
   "metadata": {
    "id": "FzHauKTMML4A",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ресурсы:\n",
    "\n",
    "#### Насчет улучшения и так хорошей модели:\n",
    "- [Общая информация](https://www.freecodecamp.org/news/improve-image-recognition-model-accuracy-with-these-hacks/)\n",
    "- [Общая информация](https://stackoverflow.com/questions/55266853/how-to-increase-model-accuracy-in-image-classification-model)\n",
    "- [Общая информация](https://towardsdatascience.com/5-effective-ways-to-improve-the-accuracy-of-your-machine-learning-models-f1ea1f2b5d65)\n",
    "- [Общая информация](https://www.dummies.com/article/technology/information-technology/ai/machine-learning/10-ways-improve-machine-learning-models-226836/)\n",
    "- [Общая информация](https://habr.com/ru/company/otus/blog/526208/)\n",
    "\n",
    "#### Про паддинги и receptive field\n",
    "- [RF](https://theaisummer.com/receptive-field/)\n",
    "- [RF](https://www.baeldung.com/cs/cnn-receptive-field-size)\n",
    "- [Padding](https://www.geeksforgeeks.org/cnn-introduction-to-padding/)\n",
    "- Лекции Яндекса\n",
    "\n",
    "#### Все остальное\n",
    "- Гиперссылки в markdown-ячейках"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tensorflow",
   "language": "python",
   "display_name": "Python 3.9 (tensorflow2)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "pV8coj4DFso0",
    "ZOXKMm8rFso1",
    "HNkjyU9vFso6"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}